{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-20T11:48:09.343809Z","iopub.execute_input":"2023-04-20T11:48:09.344251Z","iopub.status.idle":"2023-04-20T11:48:09.392006Z","shell.execute_reply.started":"2023-04-20T11:48:09.344213Z","shell.execute_reply":"2023-04-20T11:48:09.391021Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/goodreadscleaned/df.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/goodreadscleaned/df.csv')","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:48:09.394031Z","iopub.execute_input":"2023-04-20T11:48:09.394734Z","iopub.status.idle":"2023-04-20T11:49:00.365530Z","shell.execute_reply.started":"2023-04-20T11:48:09.394696Z","shell.execute_reply":"2023-04-20T11:49:00.363928Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Cluster the books based on the description. ","metadata":{}},{"cell_type":"code","source":"#importing basic python libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# text preprocessing\nimport regex\nimport nltk\n\n#word embedding\nimport gensim\n\n#clustering\nimport sklearn\n\n#connection to data scoursce in Hana cloud\n#import hana_ml\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:00.367276Z","iopub.execute_input":"2023-04-20T11:49:00.367769Z","iopub.status.idle":"2023-04-20T11:49:02.427731Z","shell.execute_reply.started":"2023-04-20T11:49:00.367717Z","shell.execute_reply":"2023-04-20T11:49:02.426703Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import re, string\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\n#import contractions\n#from sklearn.feature_extraction.text import TfidVectorizer","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:02.430332Z","iopub.execute_input":"2023-04-20T11:49:02.430985Z","iopub.status.idle":"2023-04-20T11:49:02.436217Z","shell.execute_reply.started":"2023-04-20T11:49:02.430941Z","shell.execute_reply":"2023-04-20T11:49:02.434769Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:02.439276Z","iopub.execute_input":"2023-04-20T11:49:02.439665Z","iopub.status.idle":"2023-04-20T11:49:02.484182Z","shell.execute_reply.started":"2023-04-20T11:49:02.439627Z","shell.execute_reply":"2023-04-20T11:49:02.482573Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"    book_id  author_id              authors  \\\n0   2767052     153394      Suzanne Collins   \n1         3    1077326         J.K. Rowling   \n2      2657       1825           Harper Lee   \n3      4671       3190  F. Scott Fitzgerald   \n4  11870085    1406384           John Green   \n\n                                               title  \\\n0            The Hunger Games (The Hunger Games, #1)   \n1  Harry Potter and the Sorcerer's Stone (Harry P...   \n2                              To Kill a Mockingbird   \n3                                   The Great Gatsby   \n4                             The Fault in Our Stars   \n\n                                         description  \\\n0  Winning will make you famous.\\nLosing means ce...   \n1  Harry Potter's life is miserable. His parents ...   \n2  The unforgettable novel of a childhood in a sl...   \n3  THE GREAT GATSBY, F. Scott Fitzgerald's third ...   \n4  There is an alternate cover edition \u0001.\\n\"I fel...   \n\n                          publisher  \\\n0                  Scholastic Press   \n1                    Scholastic Inc   \n2  Harper Perennial Modern Classics   \n3                          Scribner   \n4                      Dutton Books   \n\n                                              genres  avg_rating  \\\n0  ['favorites', 'currently-reading', 'to-read', ...        4.34   \n1  ['to-read', 'favorites', 'fantasy', 'young-adu...        4.45   \n2  ['to-read', 'favorites', 'classics', 'classic'...        4.26   \n3  ['to-read', 'classics', 'favorites', 'fiction'...        3.89   \n4  ['to-read', 'favorites', 'young-adult', 'ficti...        4.26   \n\n   ratings_count  num_pages  pub_year  \\\n0        4899965        374    2008.0   \n1        4765497        320    1997.0   \n2        3255518        324    2006.0   \n3        2758812        180    2004.0   \n4        2429317        313    2012.0   \n\n                                       similar_books  \\\n0  ['1902241', '146499', '954674', '9917938', '10...   \n1  ['13830', '127586', '121822', '37586', '616435...   \n2  ['1934', '2156', '15638', '53835', '77142', '5...   \n3  ['48203', '337113', '176972', '188087', '10956...   \n4  ['10051706', '11418182', '10327303', '9627755'...   \n\n                                                 url  \n0  https://www.goodreads.com/book/show/2767052-th...  \n1  https://www.goodreads.com/book/show/3.Harry_Po...  \n2  https://www.goodreads.com/book/show/2657.To_Ki...  \n3  https://www.goodreads.com/book/show/4671.The_G...  \n4  https://www.goodreads.com/book/show/11870085-t...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>author_id</th>\n      <th>authors</th>\n      <th>title</th>\n      <th>description</th>\n      <th>publisher</th>\n      <th>genres</th>\n      <th>avg_rating</th>\n      <th>ratings_count</th>\n      <th>num_pages</th>\n      <th>pub_year</th>\n      <th>similar_books</th>\n      <th>url</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2767052</td>\n      <td>153394</td>\n      <td>Suzanne Collins</td>\n      <td>The Hunger Games (The Hunger Games, #1)</td>\n      <td>Winning will make you famous.\\nLosing means ce...</td>\n      <td>Scholastic Press</td>\n      <td>['favorites', 'currently-reading', 'to-read', ...</td>\n      <td>4.34</td>\n      <td>4899965</td>\n      <td>374</td>\n      <td>2008.0</td>\n      <td>['1902241', '146499', '954674', '9917938', '10...</td>\n      <td>https://www.goodreads.com/book/show/2767052-th...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>1077326</td>\n      <td>J.K. Rowling</td>\n      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n      <td>Harry Potter's life is miserable. His parents ...</td>\n      <td>Scholastic Inc</td>\n      <td>['to-read', 'favorites', 'fantasy', 'young-adu...</td>\n      <td>4.45</td>\n      <td>4765497</td>\n      <td>320</td>\n      <td>1997.0</td>\n      <td>['13830', '127586', '121822', '37586', '616435...</td>\n      <td>https://www.goodreads.com/book/show/3.Harry_Po...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2657</td>\n      <td>1825</td>\n      <td>Harper Lee</td>\n      <td>To Kill a Mockingbird</td>\n      <td>The unforgettable novel of a childhood in a sl...</td>\n      <td>Harper Perennial Modern Classics</td>\n      <td>['to-read', 'favorites', 'classics', 'classic'...</td>\n      <td>4.26</td>\n      <td>3255518</td>\n      <td>324</td>\n      <td>2006.0</td>\n      <td>['1934', '2156', '15638', '53835', '77142', '5...</td>\n      <td>https://www.goodreads.com/book/show/2657.To_Ki...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4671</td>\n      <td>3190</td>\n      <td>F. Scott Fitzgerald</td>\n      <td>The Great Gatsby</td>\n      <td>THE GREAT GATSBY, F. Scott Fitzgerald's third ...</td>\n      <td>Scribner</td>\n      <td>['to-read', 'classics', 'favorites', 'fiction'...</td>\n      <td>3.89</td>\n      <td>2758812</td>\n      <td>180</td>\n      <td>2004.0</td>\n      <td>['48203', '337113', '176972', '188087', '10956...</td>\n      <td>https://www.goodreads.com/book/show/4671.The_G...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11870085</td>\n      <td>1406384</td>\n      <td>John Green</td>\n      <td>The Fault in Our Stars</td>\n      <td>There is an alternate cover edition \u0001.\\n\"I fel...</td>\n      <td>Dutton Books</td>\n      <td>['to-read', 'favorites', 'young-adult', 'ficti...</td>\n      <td>4.26</td>\n      <td>2429317</td>\n      <td>313</td>\n      <td>2012.0</td>\n      <td>['10051706', '11418182', '10327303', '9627755'...</td>\n      <td>https://www.goodreads.com/book/show/11870085-t...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df = df.drop('url', axis =1)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:02.485664Z","iopub.execute_input":"2023-04-20T11:49:02.487005Z","iopub.status.idle":"2023-04-20T11:49:02.612833Z","shell.execute_reply.started":"2023-04-20T11:49:02.486949Z","shell.execute_reply":"2023-04-20T11:49:02.611844Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Cleaning Description Column","metadata":{}},{"cell_type":"code","source":"books = df[['book_id','title','description']]\nbooks.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:02.614354Z","iopub.execute_input":"2023-04-20T11:49:02.614777Z","iopub.status.idle":"2023-04-20T11:49:02.676125Z","shell.execute_reply.started":"2023-04-20T11:49:02.614734Z","shell.execute_reply":"2023-04-20T11:49:02.674500Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"    book_id                                              title  \\\n0   2767052            The Hunger Games (The Hunger Games, #1)   \n1         3  Harry Potter and the Sorcerer's Stone (Harry P...   \n2      2657                              To Kill a Mockingbird   \n3      4671                                   The Great Gatsby   \n4  11870085                             The Fault in Our Stars   \n\n                                         description  \n0  Winning will make you famous.\\nLosing means ce...  \n1  Harry Potter's life is miserable. His parents ...  \n2  The unforgettable novel of a childhood in a sl...  \n3  THE GREAT GATSBY, F. Scott Fitzgerald's third ...  \n4  There is an alternate cover edition \u0001.\\n\"I fel...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>title</th>\n      <th>description</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2767052</td>\n      <td>The Hunger Games (The Hunger Games, #1)</td>\n      <td>Winning will make you famous.\\nLosing means ce...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n      <td>Harry Potter's life is miserable. His parents ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2657</td>\n      <td>To Kill a Mockingbird</td>\n      <td>The unforgettable novel of a childhood in a sl...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4671</td>\n      <td>The Great Gatsby</td>\n      <td>THE GREAT GATSBY, F. Scott Fitzgerald's third ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11870085</td>\n      <td>The Fault in Our Stars</td>\n      <td>There is an alternate cover edition \u0001.\\n\"I fel...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## 1. Text Preprocessing","metadata":{}},{"cell_type":"markdown","source":"**Tokenization**: The text in the descriotion column must be parsed and transform into a list of words.\n\n**Remove special characters and punctuation**\n\n**Remove \"stop words\"**: Commonly used words without any specific connocation (e.g., \"the\",\"a\", \"an\", \"in\")\n\n**Use Natural Language Toolkit (NLTK) and Regular Expressions (RegEx)** to clean up and tokenize our text.\n\n","metadata":{"execution":{"iopub.status.busy":"2023-04-19T16:09:03.822781Z","iopub.execute_input":"2023-04-19T16:09:03.823301Z","iopub.status.idle":"2023-04-19T16:09:03.838411Z","shell.execute_reply.started":"2023-04-19T16:09:03.823257Z","shell.execute_reply":"2023-04-19T16:09:03.836179Z"}}},{"cell_type":"code","source":"#Dropping the missing values\nbooks = books.dropna(axis = 0 , subset = [\"description\"])","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:02.678800Z","iopub.execute_input":"2023-04-20T11:49:02.679376Z","iopub.status.idle":"2023-04-20T11:49:02.926138Z","shell.execute_reply.started":"2023-04-20T11:49:02.679317Z","shell.execute_reply":"2023-04-20T11:49:02.924709Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Prepare the book description column \nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\")\nstopwords=set(stopwords.words(\"english\")) \nimport regex as re\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:02.928003Z","iopub.execute_input":"2023-04-20T11:49:02.928428Z","iopub.status.idle":"2023-04-20T11:49:03.017574Z","shell.execute_reply.started":"2023-04-20T11:49:02.928382Z","shell.execute_reply":"2023-04-20T11:49:03.016186Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# Transform to the lowercase\nbooks['tokens'] = books['description'].apply(lambda x: x.lower())","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:03.022186Z","iopub.execute_input":"2023-04-20T11:49:03.022538Z","iopub.status.idle":"2023-04-20T11:49:04.621011Z","shell.execute_reply.started":"2023-04-20T11:49:03.022505Z","shell.execute_reply":"2023-04-20T11:49:04.619849Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"books['tokens']","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:40:27.516223Z","iopub.execute_input":"2023-04-20T12:40:27.517106Z","iopub.status.idle":"2023-04-20T12:40:27.527627Z","shell.execute_reply.started":"2023-04-20T12:40:27.517046Z","shell.execute_reply":"2023-04-20T12:40:27.526220Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"0         winning make famous losing means certain death...\n1         harry potter life miserable parents dead stuck...\n2         unforgettable novel childhood sleepy southern ...\n3         great gatsby scott fitzgerald third book stand...\n4         alternate cover edition \"i fell love way fall ...\n                                ...                        \n869626    system solve problem harry leonnoff fix power ...\n869627    ruth hard life see way sees charmed happy howe...\n869628    examines history culture changing fortunes len...\n869629    july 1937 beloved amelia lost mid pacific crea...\n869630    cambridge scholar nathan tobin discovers ancie...\nName: tokens, Length: 826846, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"#Remove punctuations\nbooks['tokens']  = books['tokens'].map(lambda x: re.sub(\"[-,\\.!?;\\'\\(\\)]\", ' ',x))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:04.622383Z","iopub.execute_input":"2023-04-20T11:49:04.622711Z","iopub.status.idle":"2023-04-20T11:49:24.882554Z","shell.execute_reply.started":"2023-04-20T11:49:04.622679Z","shell.execute_reply":"2023-04-20T11:49:24.881284Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Remove stopwords\nbooks['tokens']  = books['tokens'].apply(lambda x: ' '.join([t for t in x.split() if not t in stopwords]))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:24.883976Z","iopub.execute_input":"2023-04-20T11:49:24.884336Z","iopub.status.idle":"2023-04-20T11:49:49.788196Z","shell.execute_reply.started":"2023-04-20T11:49:24.884302Z","shell.execute_reply":"2023-04-20T11:49:49.786810Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"#Remove short tokens\nbooks['tokens'] = books['tokens'].apply(lambda x:' '.join([t for t in x.split()if len(t)>1]))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:49:49.789954Z","iopub.execute_input":"2023-04-20T11:49:49.790480Z","iopub.status.idle":"2023-04-20T11:50:05.381034Z","shell.execute_reply.started":"2023-04-20T11:49:49.790418Z","shell.execute_reply":"2023-04-20T11:50:05.379701Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"#Remove extra spaces\nbooks['tokens'] = books['tokens'].map(lambda x: re.sub(' +', ' ', x))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:50:05.382769Z","iopub.execute_input":"2023-04-20T11:50:05.383288Z","iopub.status.idle":"2023-04-20T11:50:31.886115Z","shell.execute_reply.started":"2023-04-20T11:50:05.383244Z","shell.execute_reply":"2023-04-20T11:50:31.884813Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#Remove duplicate tokens\nbooks['tokens'] = books['tokens'].apply(lambda x: ' '.join(list(dict.fromkeys(x.split()))))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:50:31.887490Z","iopub.execute_input":"2023-04-20T11:50:31.887821Z","iopub.status.idle":"2023-04-20T11:50:46.874449Z","shell.execute_reply.started":"2023-04-20T11:50:31.887790Z","shell.execute_reply":"2023-04-20T11:50:46.873126Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Drop the duplicates\nbooks = books.drop_duplicates('tokens')","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:50:46.876084Z","iopub.execute_input":"2023-04-20T11:50:46.876569Z","iopub.status.idle":"2023-04-20T11:50:48.605032Z","shell.execute_reply.started":"2023-04-20T11:50:46.876517Z","shell.execute_reply":"2023-04-20T11:50:48.603519Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Remove any non-alphanumeric characters\n#books['tokens']=books['tokens'].apply(lambda x: ' '.join([re.sub('[^A-Za-z]+','', x) for x in nltk.word_tokenize(x)]))","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:50:48.607299Z","iopub.execute_input":"2023-04-20T11:50:48.607802Z","iopub.status.idle":"2023-04-20T11:50:48.616055Z","shell.execute_reply.started":"2023-04-20T11:50:48.607749Z","shell.execute_reply":"2023-04-20T11:50:48.614415Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"books[['book_id', 'title', 'description','tokens']]","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:50:48.618073Z","iopub.execute_input":"2023-04-20T11:50:48.619026Z","iopub.status.idle":"2023-04-20T11:50:48.692687Z","shell.execute_reply.started":"2023-04-20T11:50:48.618929Z","shell.execute_reply":"2023-04-20T11:50:48.691297Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"         book_id                                              title  \\\n0        2767052            The Hunger Games (The Hunger Games, #1)   \n1              3  Harry Potter and the Sorcerer's Stone (Harry P...   \n2           2657                              To Kill a Mockingbird   \n3           4671                                   The Great Gatsby   \n4       11870085                             The Fault in Our Stars   \n...          ...                                                ...   \n869626   2314733                                              Fixer   \n869627  26733966                                            Wake Up   \n869628   1040719                            The Lenapes (Paperback)   \n869629  15775045                       Amelia Earhart--Case Closed!   \n869630   7674832                              The Alexandria Letter   \n\n                                              description  \\\n0       Winning will make you famous.\\nLosing means ce...   \n1       Harry Potter's life is miserable. His parents ...   \n2       The unforgettable novel of a childhood in a sl...   \n3       THE GREAT GATSBY, F. Scott Fitzgerald's third ...   \n4       There is an alternate cover edition \u0001.\\n\"I fel...   \n...                                                   ...   \n869626  If the system won't solve your problem, Harry ...   \n869627  Ruth has had a hard life, but she doesn't see ...   \n869628  Examines the history, culture, and changing fo...   \n869629  On July 2, 1937 our beloved Amelia was lost ov...   \n869630  After Cambridge scholar Nathan Tobin discovers...   \n\n                                                   tokens  \n0       winning make famous losing means certain death...  \n1       harry potter life miserable parents dead stuck...  \n2       unforgettable novel childhood sleepy southern ...  \n3       great gatsby scott fitzgerald third book stand...  \n4       alternate cover edition \"i fell love way fall ...  \n...                                                   ...  \n869626  system solve problem harry leonnoff fix power ...  \n869627  ruth hard life see way sees charmed happy howe...  \n869628  examines history culture changing fortunes len...  \n869629  july 1937 beloved amelia lost mid pacific crea...  \n869630  cambridge scholar nathan tobin discovers ancie...  \n\n[826846 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_id</th>\n      <th>title</th>\n      <th>description</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2767052</td>\n      <td>The Hunger Games (The Hunger Games, #1)</td>\n      <td>Winning will make you famous.\\nLosing means ce...</td>\n      <td>winning make famous losing means certain death...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>Harry Potter and the Sorcerer's Stone (Harry P...</td>\n      <td>Harry Potter's life is miserable. His parents ...</td>\n      <td>harry potter life miserable parents dead stuck...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2657</td>\n      <td>To Kill a Mockingbird</td>\n      <td>The unforgettable novel of a childhood in a sl...</td>\n      <td>unforgettable novel childhood sleepy southern ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4671</td>\n      <td>The Great Gatsby</td>\n      <td>THE GREAT GATSBY, F. Scott Fitzgerald's third ...</td>\n      <td>great gatsby scott fitzgerald third book stand...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11870085</td>\n      <td>The Fault in Our Stars</td>\n      <td>There is an alternate cover edition \u0001.\\n\"I fel...</td>\n      <td>alternate cover edition \"i fell love way fall ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>869626</th>\n      <td>2314733</td>\n      <td>Fixer</td>\n      <td>If the system won't solve your problem, Harry ...</td>\n      <td>system solve problem harry leonnoff fix power ...</td>\n    </tr>\n    <tr>\n      <th>869627</th>\n      <td>26733966</td>\n      <td>Wake Up</td>\n      <td>Ruth has had a hard life, but she doesn't see ...</td>\n      <td>ruth hard life see way sees charmed happy howe...</td>\n    </tr>\n    <tr>\n      <th>869628</th>\n      <td>1040719</td>\n      <td>The Lenapes (Paperback)</td>\n      <td>Examines the history, culture, and changing fo...</td>\n      <td>examines history culture changing fortunes len...</td>\n    </tr>\n    <tr>\n      <th>869629</th>\n      <td>15775045</td>\n      <td>Amelia Earhart--Case Closed!</td>\n      <td>On July 2, 1937 our beloved Amelia was lost ov...</td>\n      <td>july 1937 beloved amelia lost mid pacific crea...</td>\n    </tr>\n    <tr>\n      <th>869630</th>\n      <td>7674832</td>\n      <td>The Alexandria Letter</td>\n      <td>After Cambridge scholar Nathan Tobin discovers...</td>\n      <td>cambridge scholar nathan tobin discovers ancie...</td>\n    </tr>\n  </tbody>\n</table>\n<p>826846 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Rescources on techniques for pre-processing:\n* https://tutorialspoint.dev/language/python/removing-stop-words-nltk-python \n* https://en.wikipedia.org/wiki/Regular_expression","metadata":{}},{"cell_type":"markdown","source":"## Word Embedding","metadata":{}},{"cell_type":"markdown","source":"**Use Global Vectors for Word Representation (GloVe):** GloVe is a word2vec model that is to say an unsupervised learning algorithm for obtaining vector representations for words.It allows you to take any corpus of text and transform each word into a position in high-dimentional space. \n    \n**Download a pretrained model** that was trained on a broder corpus:Wikipidia\nEach line of text file contains a word follow by N number. The N number describe the vector of the word position. N is varid depending on which model you choose to download. \n    \n    \n**More Resources:** \n* https://faculty.ai/tech-blog/glove/\n* https://medium.com/analytics-vidhya/basics-of-using-pre-trained-glove-vectors-in-python-d38905f356db \n","metadata":{}},{"cell_type":"code","source":"import gensim.downloader as gensim_api","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:50:48.695084Z","iopub.execute_input":"2023-04-20T11:50:48.695607Z","iopub.status.idle":"2023-04-20T11:50:48.702819Z","shell.execute_reply.started":"2023-04-20T11:50:48.695499Z","shell.execute_reply":"2023-04-20T11:50:48.701482Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model = gensim_api.load(\"glove-wiki-gigaword-100\")","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:50:48.704490Z","iopub.execute_input":"2023-04-20T11:50:48.705334Z","iopub.status.idle":"2023-04-20T11:51:41.824792Z","shell.execute_reply.started":"2023-04-20T11:50:48.705270Z","shell.execute_reply":"2023-04-20T11:51:41.823745Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"[==================================================] 100.0% 128.1/128.1MB downloaded\n","output_type":"stream"}]},{"cell_type":"code","source":"books['tokens'] = books['tokens'].astype(str)","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:44:14.795787Z","iopub.execute_input":"2023-04-20T12:44:14.796256Z","iopub.status.idle":"2023-04-20T12:44:14.929769Z","shell.execute_reply.started":"2023-04-20T12:44:14.796217Z","shell.execute_reply":"2023-04-20T12:44:14.928666Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom gensim.models import Word2Vec\n\n\n# generate embedded features for each book\nfeatures = []\nfor tokens in books['tokens']:\n    token_features = []\n    for token in tokens:\n        try:\n            token_features.append(model[token])\n        except KeyError:\n            continue\n    features.append(np.mean(token_features, axis=0))\n\n# add features to DataFrame\nfor i in range(100):\n    feature = 'f_' + str(i)\n    books[feature] = [f[i] for f in features]\n\n# define embedding column names\nembedding = ['f_' + str(i) for i in range(100)]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:58:49.704533Z","iopub.execute_input":"2023-04-20T12:58:49.704981Z","iopub.status.idle":"2023-04-20T13:14:09.295962Z","shell.execute_reply.started":"2023-04-20T12:58:49.704945Z","shell.execute_reply":"2023-04-20T13:14:09.293823Z"},"trusted":true},"execution_count":43,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1765332533.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# define embedding column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1765332533.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'f_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# define embedding column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."],"ename":"IndexError","evalue":"invalid index to scalar variable.","output_type":"error"}]},{"cell_type":"code","source":"# create an empty array to hold the feature vectors\nfeatures = np.zeros((len(books), 100))\n\n# loop over each book description and compute the average embedding\nfor i, tokens in enumerate(books['tokens']):\n    token_list = tokens.split()\n    embeddings = []\n    for token in token_list:\n        if token in model:\n            embeddings.append(model[token])\n    if len(embeddings) > 0:\n        avg_embedding = np.mean(embeddings, axis=0)\n    else:\n        avg_embedding = np.zeros(100)\n    features[i] = avg_embedding\n\n# add the features to the dataframe\nfor i in range(100):\n    feature = 'f_' + str(i)\n    books[feature] = features[:, i]\n\n# create a list of the embedding feature names\nembedding = ['f_' + str(i) for i in range(100)]\n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T13:15:48.090296Z","iopub.execute_input":"2023-04-20T13:15:48.090699Z","iopub.status.idle":"2023-04-20T13:19:27.357928Z","shell.execute_reply.started":"2023-04-20T13:15:48.090665Z","shell.execute_reply":"2023-04-20T13:19:27.356214Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n","output_type":"stream"}]},{"cell_type":"code","source":"#Now that we downloaded tour word2vec model, we can apply it to every book description to embed the book into a multidimentional space.\nfeatures=[]\nfor i,book in books.iterrows():\n    tokens_features=[]\n    for word in book['tokens'].split():\n        try:\n            tokens_features.append(model[word])\n        except:\n            continue\n    features.append(np.mean(np.array(tokens_features),axis=0))\n    \n","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:44:17.502329Z","iopub.execute_input":"2023-04-20T12:44:17.502757Z","iopub.status.idle":"2023-04-20T12:48:34.581714Z","shell.execute_reply.started":"2023-04-20T12:44:17.502720Z","shell.execute_reply":"2023-04-20T12:48:34.580107Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"for i in range(100):\n    feature='f_'+str(i)\n    books[feature]=[f[i] for f in features]\nembedding=['f_'+str(i) for i in range(100)]","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:54:13.706264Z","iopub.execute_input":"2023-04-20T12:54:13.706703Z","iopub.status.idle":"2023-04-20T12:54:13.756128Z","shell.execute_reply.started":"2023-04-20T12:54:13.706665Z","shell.execute_reply":"2023-04-20T12:54:13.753994Z"},"trusted":true},"execution_count":39,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/4282246652.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/4282246652.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'f_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."],"ename":"IndexError","evalue":"invalid index to scalar variable.","output_type":"error"}]},{"cell_type":"code","source":"embedding=['f_'+str(i) for i in range(100)]","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:51:58.257994Z","iopub.execute_input":"2023-04-20T12:51:58.258430Z","iopub.status.idle":"2023-04-20T12:51:58.265425Z","shell.execute_reply.started":"2023-04-20T12:51:58.258392Z","shell.execute_reply":"2023-04-20T12:51:58.263783Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"for i in range(100):\n    feature='f_'+str(i)\n    books[feature]=[f[i] for f in features]\n    \n    \n#del features\n#embedding=['f_'+str(i) for i in range(100)]","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:51:25.980278Z","iopub.execute_input":"2023-04-20T12:51:25.980708Z","iopub.status.idle":"2023-04-20T12:51:26.029900Z","shell.execute_reply.started":"2023-04-20T12:51:25.980670Z","shell.execute_reply":"2023-04-20T12:51:26.027672Z"},"trusted":true},"execution_count":33,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/1381127185.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_27/1381127185.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mfeature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'f_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mbooks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."],"ename":"IndexError","evalue":"invalid index to scalar variable.","output_type":"error"}]},{"cell_type":"code","source":"#As a resulting of our word embedding technique we associated each book to a 100 -dim numerical vector:\nbooks[['title']+embedding]","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:55:53.668662Z","iopub.status.idle":"2023-04-20T11:55:53.669084Z","shell.execute_reply.started":"2023-04-20T11:55:53.668881Z","shell.execute_reply":"2023-04-20T11:55:53.668903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"books.info()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T12:41:11.527427Z","iopub.execute_input":"2023-04-20T12:41:11.527838Z","iopub.status.idle":"2023-04-20T12:41:12.070710Z","shell.execute_reply.started":"2023-04-20T12:41:11.527802Z","shell.execute_reply":"2023-04-20T12:41:12.069198Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nInt64Index: 826846 entries, 0 to 869630\nData columns (total 4 columns):\n #   Column       Non-Null Count   Dtype \n---  ------       --------------   ----- \n 0   book_id      826846 non-null  int64 \n 1   title        826846 non-null  object\n 2   description  826846 non-null  object\n 3   tokens       826846 non-null  object\ndtypes: int64(1), object(3)\nmemory usage: 31.5+ MB\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KMeans Clustering","metadata":{}},{"cell_type":"markdown","source":"Now that we have represented each book by a point in a multidimentional space, we can use the distance between each books to find out which books are similar to each other. \n\n**Using Cluster Analysis**: The similar books will be grouped togther.\n\n**Setting the number of group to 10**: We use KMeans clustering algorithm in the form og MiniBatchKmeans","metadata":{}},{"cell_type":"code","source":"from sklearn.cluster import MiniBatchKMeans","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:55:53.671394Z","iopub.status.idle":"2023-04-20T11:55:53.672000Z","shell.execute_reply.started":"2023-04-20T11:55:53.671686Z","shell.execute_reply":"2023-04-20T11:55:53.671718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_clus =10\nkm = MiniBatchKMeans(n_clusters = n_clus, bach_size = 50, random_state = 42, max_iter = 1000)\ny_kmeans = km.fit_predict(books[embedding])\nbooks['kmeans_cluster']= y_kmeans","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:55:53.673973Z","iopub.status.idle":"2023-04-20T11:55:53.674580Z","shell.execute_reply.started":"2023-04-20T11:55:53.674277Z","shell.execute_reply":"2023-04-20T11:55:53.674309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cluster Profiling","metadata":{}},{"cell_type":"markdown","source":"Examine the most representative book from each cluster to see if the clustering work effectively.","metadata":{}},{"cell_type":"code","source":"for cluster in range(n_clus):\n    print('************* ')\n    print('- CLUSTER ',str(cluster))\n    print('*************')\n    bks=books[books['kmeans_cluster']==cluster]\n    most_representative_docs = np.argsort(\n    np.linalg.norm(bks[embedding] - km.cluster_centers_[cluster], axis=1)\n)\n    del bks\n    centroid_index= most_representative_docs[0]\n    centroid=[]\n    for i in range(100):\n        feature='f_'+str(i)\n    for d in most_representative_docs[:10]:\n        print(books.reset_index().Book_Description[d])\n        print(\"--\")","metadata":{"execution":{"iopub.status.busy":"2023-04-20T11:55:53.676676Z","iopub.status.idle":"2023-04-20T11:55:53.677275Z","shell.execute_reply.started":"2023-04-20T11:55:53.676947Z","shell.execute_reply":"2023-04-20T11:55:53.676979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can notice a certain homogeneity between the descriptions belongingto the same ","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}